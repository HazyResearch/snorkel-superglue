{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiRC Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TASK_NAME = \"MultiRC\"\n",
    "BERT_MODEL = \"bert-large-cased\"\n",
    "\n",
    "dataloader_config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"data_dir\": os.environ[\"SUPERGLUEDATA\"],\n",
    "    \"splits\": [\"train\", \"valid\"],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 1e-5,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"n_epochs\": 10,\n",
    "    \"conter_unit\": \"epochs\",\n",
    "    \"evaluation_freq\": 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import get_dataloaders\n",
    "\n",
    "dataloaders = get_dataloaders(\n",
    "    task_name=TASK_NAME,\n",
    "    tokenizer_name=BERT_MODEL,\n",
    "    **dataloader_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242874899/1242874899 [01:57<00:00, 10594637.26B/s]\n"
     ]
    }
   ],
   "source": [
    "from superglue_tasks import task_funcs\n",
    "\n",
    "task = task_funcs[TASK_NAME](BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a TF that pulls out just the sentences in the \"sentences_used\" field \n",
    "# associated with each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the TF to get the updated dataloaders\n",
    "# Make sure you apply it to all splits so that train/valid don't have wildly \n",
    "# different distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.mtl.model import MultitaskModel\n",
    "\n",
    "model = MultitaskModel(tasks=[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.mtl.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(**trainer_config)\n",
    "trainer.train_model(model, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill after you start training\n",
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model score\n",
    "# Pretty print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to non-transformed model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load non-slice model\n",
    "# Score\n",
    "# See the gap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel_env",
   "language": "python",
   "name": "snorkel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
