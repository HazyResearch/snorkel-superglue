{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTE Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "if not \"cwd\" in globals():\n",
    "    cwd = Path(os.getcwd())\n",
    "sys.path.insert(0, str(cwd.parents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recognizing Textual Entailment (RTE)** is a natural language inference task that addresses whether a _premise_ sentence entails a _hypothesis_ sentence, with labels `entailment` (do the facts of the premise imply the facts of the hypothesis?) or `not_entailment`.\n",
    "\n",
    "In this notebook, we'll...\n",
    "* Write over a dozen, simple slicing functions based on an [external error analysis](https://arxiv.org/abs/1904.11544) to initialize our model\n",
    "* Load existing base architecture weights + fine-tune slice heads from pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"RTE\"\n",
    "BERT_MODEL = \"bert-large-cased\"\n",
    "\n",
    "dataloader_config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"data_dir\": os.environ.get(\"SUPERGLUEDATA\", os.path.join(str(cwd.parents[0]), \"data\")),\n",
    "    \"splits\": [\"train\", \"valid\"],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 2e-5,\n",
    "    \"optimizer\": \"adamax\",\n",
    "    \"n_epochs\": 15,\n",
    "    \"conter_unit\": \"epochs\",\n",
    "    \"evaluation_freq\": 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import get_dataloaders\n",
    "\n",
    "dataloaders = get_dataloaders(\n",
    "    task_name=TASK_NAME,\n",
    "    tokenizer_name=BERT_MODEL,\n",
    "    **dataloader_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from superglue_tasks import task_funcs\n",
    "\n",
    "task = task_funcs[TASK_NAME](BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.mtl.model import MultitaskModel\n",
    "from snorkel.mtl.trainer import Trainer\n",
    "\n",
    "vanilla_model = MultitaskModel(tasks=[task], device=-1, dataparallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following to train the vanilla BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(**trainer_config)\n",
    "# trainer.train_model(model, dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, use the one we pretrained for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-03 02:29:42--  https://www.dropbox.com/s/t2ri9o0iz765hsn/RTE_bert.pth?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/t2ri9o0iz765hsn/RTE_bert.pth [following]\n",
      "--2019-08-03 02:29:42--  https://www.dropbox.com/s/raw/t2ri9o0iz765hsn/RTE_bert.pth\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com/cd/0/inline/Al5oQsN8nPiXmd76VfWT4E-0_-3Az1cm2_e0F-o3CUmCaVLMwc9zuMSjONvW-JYSiMSsX7SQ0MXCFXrO5xRcBND-WsHf-oQZn_f8NgEWQUT5qQ/file# [following]\n",
      "--2019-08-03 02:29:42--  https://uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com/cd/0/inline/Al5oQsN8nPiXmd76VfWT4E-0_-3Az1cm2_e0F-o3CUmCaVLMwc9zuMSjONvW-JYSiMSsX7SQ0MXCFXrO5xRcBND-WsHf-oQZn_f8NgEWQUT5qQ/file\n",
      "Resolving uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com (uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
      "Connecting to uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com (uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/Al43-Y7VshBs6UOEZI-i1Vr3d_-DsITvpGef2iei-XF-vcEf74mscHhxOLztPZoJCslDWQSwaZ847C185K9PWOQgQN4jDyDEfVS5ufypgdDfJ7MeWYx-oKlNpJYgAIM9D5A6v2eSamJZAdin2ILuTQ13-NblUIPp8uF6ua3amDMRhfD8hgcBJk5VJAAoYmu2APGy-AIPu6bHBiLQZv1FfXAd-MKFRFUXy2Cj81lbx1KGADDPYKz2nSwZC_6DES_Ay6WAaxgXieI_1qBr9ZIPk-HOGp9kFFVhAsXlzMvm0z05BvfS-1RiM2Y4GBTUq8ivR0nWnHQE3eIy-35-4Q2Fw5jN/file [following]\n",
      "--2019-08-03 02:29:44--  https://uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com/cd/0/inline2/Al43-Y7VshBs6UOEZI-i1Vr3d_-DsITvpGef2iei-XF-vcEf74mscHhxOLztPZoJCslDWQSwaZ847C185K9PWOQgQN4jDyDEfVS5ufypgdDfJ7MeWYx-oKlNpJYgAIM9D5A6v2eSamJZAdin2ILuTQ13-NblUIPp8uF6ua3amDMRhfD8hgcBJk5VJAAoYmu2APGy-AIPu6bHBiLQZv1FfXAd-MKFRFUXy2Cj81lbx1KGADDPYKz2nSwZC_6DES_Ay6WAaxgXieI_1qBr9ZIPk-HOGp9kFFVhAsXlzMvm0z05BvfS-1RiM2Y4GBTUq8ivR0nWnHQE3eIy-35-4Q2Fw5jN/file\n",
      "Reusing existing connection to uc7b1e1f2940115de24b24e5659c.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1334429106 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘RTE_bert.pth?dl=0’\n",
      "\n",
      "RTE_bert.pth?dl=0   100%[===================>]   1.24G  36.6MB/s    in 37s     \n",
      "\n",
      "2019-08-03 02:30:22 (34.4 MB/s) - ‘RTE_bert.pth?dl=0’ saved [1334429106/1334429106]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're missing the model, uncomment this line:\n",
    "# ! wget -nc https://www.dropbox.com/s/t2ri9o0iz765hsn/RTE_bert.pth?dl=0 && mv RTE_bert.pth?dl=0 RTE_bert.pth\n",
    "# vanilla_model.load(\"RTE_bert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 27s, sys: 8.8 s, total: 11min 36s\n",
      "Wall time: 6min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RTE/SuperGLUE/valid/accuracy': 0.7364620938628159}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vanilla_model.score(dataloaders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SFs\n",
    "We emphasize here that our _data slicing_ abstraction follows intuitive, programmer workflows!\n",
    "\n",
    "We rely on error buckets defined by [Kim et. al 2019](https://arxiv.org/pdf/1904.11544.pdf) to define our slices.\n",
    "Then, we apply quick-to-write, heuristics to target each of these buckets. \n",
    "Intuitively, these are slices that were important enough to be measured independently by researchers—so we'd like to write slicing functions to try and improve performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing.sf import slicing_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_temporal_preposition(example):\n",
    "    temporal_prepositions = [\"after\", \"before\", \"past\"]\n",
    "    both_sentences = example.sentence1 + example.sentence2\n",
    "    return any([p in both_sentences for p in temporal_prepositions])\n",
    "\n",
    "@slicing_function()\n",
    "def slice_possessive_preposition(example):\n",
    "    possessive_prepositions = [\"inside of\", \"with\", \"within\"]\n",
    "    both_sentences = example.sentence1 + example.sentence2\n",
    "    return any([p in both_sentences for p in possessive_prepositions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_is_comparative(example):\n",
    "    comparative_words = [\"more\", \"less\", \"better\", \"worse\", \"bigger\", \"smaller\"]\n",
    "    both_sentences = example.sentence1 + example.sentence2\n",
    "    return any([p in both_sentences for p in comparative_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_is_quantification(example):\n",
    "    quantification_words = [\"all\", \"some\", \"none\"]\n",
    "    both_sentences = example.sentence1 + example.sentence2\n",
    "    return any([p in both_sentences for p in quantification_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wh-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_where(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"where\" in sentences\n",
    "\n",
    "@slicing_function()\n",
    "def slice_who(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"who\" in sentences\n",
    "\n",
    "@slicing_function()\n",
    "def slice_what(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"what\" in sentences\n",
    "\n",
    "@slicing_function()\n",
    "def slice_when(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"when\" in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinating Conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_and(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"and\" in sentences\n",
    "\n",
    "@slicing_function()\n",
    "def slice_but(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"but\" in sentences\n",
    "\n",
    "@slicing_function()\n",
    "def slice_or(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    return \"or\" in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definite-Indefinite Articles\n",
    "Multiple occurences of articles like `the` or `an` might refer to different entities—we try to heuristically capture this here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_multiple_articles(example):\n",
    "    sentences = example.sentence1 + example.sentence2\n",
    "    multiple_indefinite = sum([int(x == \"a\") for x in sentences.split()]) > 1 \\\n",
    "        or sum([int(x == \"an\") for x in sentences.split()]) > 1\n",
    "    multiple_definite = sum([int(x == \"the\") for x in sentences.split()]) > 1\n",
    "    return multiple_indefinite or multiple_definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Misc.) Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_short_hypothesis(example, thresh=5):\n",
    "    return len(example.sentence2.split()) < thresh\n",
    "\n",
    "@slicing_function()\n",
    "def slice_long_hypothesis(example, thresh=15):\n",
    "    return len(example.sentence2.split()) > thresh\n",
    "\n",
    "@slicing_function()\n",
    "def slice_short_premise(example, thresh=10):\n",
    "    return len(example.sentence1.split()) < thresh\n",
    "\n",
    "@slicing_function()\n",
    "def slice_long_premise(example, thresh=100):\n",
    "    return len(example.sentence1.split()) > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add slices to dataloaders and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicing_functions = [\n",
    "    slice_temporal_preposition,\n",
    "    slice_possessive_preposition,\n",
    "    slice_is_comparative,\n",
    "    slice_is_quantification,\n",
    "    slice_where,\n",
    "    slice_who,\n",
    "    slice_what,\n",
    "    slice_when,\n",
    "    slice_and,\n",
    "    slice_or,\n",
    "    slice_but,\n",
    "    slice_multiple_articles,\n",
    "    slice_short_hypothesis,\n",
    "    slice_long_hypothesis,\n",
    "    slice_short_premise,\n",
    "    slice_long_premise\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_names = [sf.name for sf in slicing_functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(name=RTE_slice:slice_temporal_preposition_ind),\n",
       " Task(name=RTE_slice:slice_possessive_preposition_ind),\n",
       " Task(name=RTE_slice:slice_is_comparative_ind),\n",
       " Task(name=RTE_slice:slice_is_quantification_ind),\n",
       " Task(name=RTE_slice:slice_where_ind),\n",
       " Task(name=RTE_slice:slice_who_ind),\n",
       " Task(name=RTE_slice:slice_what_ind),\n",
       " Task(name=RTE_slice:slice_when_ind),\n",
       " Task(name=RTE_slice:slice_and_ind),\n",
       " Task(name=RTE_slice:slice_or_ind),\n",
       " Task(name=RTE_slice:slice_but_ind),\n",
       " Task(name=RTE_slice:slice_multiple_articles_ind),\n",
       " Task(name=RTE_slice:slice_short_hypothesis_ind),\n",
       " Task(name=RTE_slice:slice_long_hypothesis_ind),\n",
       " Task(name=RTE_slice:slice_short_premise_ind),\n",
       " Task(name=RTE_slice:slice_long_premise_ind),\n",
       " Task(name=RTE_slice:base_ind),\n",
       " Task(name=RTE_slice:slice_temporal_preposition_pred),\n",
       " Task(name=RTE_slice:slice_possessive_preposition_pred),\n",
       " Task(name=RTE_slice:slice_is_comparative_pred),\n",
       " Task(name=RTE_slice:slice_is_quantification_pred),\n",
       " Task(name=RTE_slice:slice_where_pred),\n",
       " Task(name=RTE_slice:slice_who_pred),\n",
       " Task(name=RTE_slice:slice_what_pred),\n",
       " Task(name=RTE_slice:slice_when_pred),\n",
       " Task(name=RTE_slice:slice_and_pred),\n",
       " Task(name=RTE_slice:slice_or_pred),\n",
       " Task(name=RTE_slice:slice_but_pred),\n",
       " Task(name=RTE_slice:slice_multiple_articles_pred),\n",
       " Task(name=RTE_slice:slice_short_hypothesis_pred),\n",
       " Task(name=RTE_slice:slice_long_hypothesis_pred),\n",
       " Task(name=RTE_slice:slice_short_premise_pred),\n",
       " Task(name=RTE_slice:slice_long_premise_pred),\n",
       " Task(name=RTE_slice:base_pred),\n",
       " Task(name=RTE)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.slicing.utils import add_slice_labels, convert_to_slice_tasks\n",
    "\n",
    "# make slices tasks\n",
    "slice_tasks = convert_to_slice_tasks(task, slice_names)\n",
    "slice_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2490/2490 [00:01<00:00, 1325.76it/s]\n",
      "100%|██████████| 277/277 [00:00<00:00, 2250.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing.apply import PandasSFApplier\n",
    "from snorkel.slicing.utils import add_slice_labels\n",
    "from utils import task_dataset_to_dataframe\n",
    "\n",
    "applier = PandasSFApplier(slicing_functions)\n",
    "\n",
    "# add slice labels\n",
    "for dl in dataloaders:\n",
    "    df = task_dataset_to_dataframe(dl.dataset)\n",
    "    S_matrix = applier.apply(df)\n",
    "    \n",
    "    # updates dataloaders in place\n",
    "    add_slice_labels(dl, task, S_matrix, slice_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_model = MultitaskModel(tasks=slice_tasks, device=-1, dataparallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from pretrained BERT\n",
    "Given that the `slice_model` shares the same backbone architecture as the `vanilla_model`, we can simply reload these backbone weights (pretrained on RTE), and then fine-tune the slicing heads!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previous backbone weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_model.load_state_dict(vanilla_model.collect_state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fine-tune the slice heads!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(**trainer_config)\n",
    "# trainer.train_model(slice_model, dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or load our pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-03 02:37:46--  https://www.dropbox.com/s/18ta5z3tzasba0m/RTE_slice_from_bert.pth\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/18ta5z3tzasba0m/RTE_slice_from_bert.pth [following]\n",
      "--2019-08-03 02:37:46--  https://www.dropbox.com/s/raw/18ta5z3tzasba0m/RTE_slice_from_bert.pth\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com/cd/0/inline/Al5se9gUr-Z28oK04O8jG_gjCnZo7O1HPLcBX4qAIG84ViLwqGLQjdD0PwxFp4Q1KAoNwhvXG7t-K4RAhZUt6h5siBuosWmfagGm4_YHQvZN-w/file# [following]\n",
      "--2019-08-03 02:37:46--  https://uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com/cd/0/inline/Al5se9gUr-Z28oK04O8jG_gjCnZo7O1HPLcBX4qAIG84ViLwqGLQjdD0PwxFp4Q1KAoNwhvXG7t-K4RAhZUt6h5siBuosWmfagGm4_YHQvZN-w/file\n",
      "Resolving uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com (uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
      "Connecting to uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com (uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/Al5-74iDY5UL_DwuJTdrOto3jZUwEkIihkXw7TUsBiiLjGHNR5NyDbfK9Z2mH3Y5OHUViQd555k6-8WM-_llEGb4vm5jmIMjKliBdBIMVKOH0Jf_CFYn934Zz12r-43AKcJsAM2KstFzcxA_sBQxQj_lo_PKubL0wUE7iYrDJqXd_i0ZnwG55uLW1MHSlqkgUzIFy3Z-TAbvd7MylTLORSkm0UPlXYwls5Kn7WBftMeKUF1OgO3Ebe5T2XFVkH5zQvJXXgtwdICHFz7xpPwQtFxKDByrsNiRuarA5-Ec24TqdDLd8dc-U-Ni4r1V25gQ9asrX5PQu_dYkkD_V713mOKi/file [following]\n",
      "--2019-08-03 02:37:47--  https://uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com/cd/0/inline2/Al5-74iDY5UL_DwuJTdrOto3jZUwEkIihkXw7TUsBiiLjGHNR5NyDbfK9Z2mH3Y5OHUViQd555k6-8WM-_llEGb4vm5jmIMjKliBdBIMVKOH0Jf_CFYn934Zz12r-43AKcJsAM2KstFzcxA_sBQxQj_lo_PKubL0wUE7iYrDJqXd_i0ZnwG55uLW1MHSlqkgUzIFy3Z-TAbvd7MylTLORSkm0UPlXYwls5Kn7WBftMeKUF1OgO3Ebe5T2XFVkH5zQvJXXgtwdICHFz7xpPwQtFxKDByrsNiRuarA5-Ec24TqdDLd8dc-U-Ni4r1V25gQ9asrX5PQu_dYkkD_V713mOKi/file\n",
      "Reusing existing connection to uc09d8e033d559292ae8c657c9bf.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1405974031 (1.3G) [application/octet-stream]\n",
      "Saving to: ‘RTE_slice_from_bert.pth’\n",
      "\n",
      "RTE_slice_from_bert 100%[===================>]   1.31G  36.5MB/s    in 38s     \n",
      "\n",
      "2019-08-03 02:38:26 (35.1 MB/s) - ‘RTE_slice_from_bert.pth’ saved [1405974031/1405974031]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're missing the model, uncomment this line:\n",
    "# ! wget -nc https://www.dropbox.com/s/18ta5z3tzasba0m/RTE_slice_from_bert.pth\n",
    "# slice_model.load(\"RTE_slice_from_bert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snorkel-superglue/.env/lib/python3.6/site-packages/snorkel/slicing/modules/slice_combiner.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  for slice_ind_name in slice_ind_op_names\n",
      "/home/ubuntu/snorkel-superglue/.env/lib/python3.6/site-packages/snorkel/slicing/modules/slice_combiner.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  for slice_pred_name in slice_pred_op_names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 9s, sys: 2.01 s, total: 10min 11s\n",
      "Wall time: 5min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RTE/SuperGLUE/valid/accuracy': 0.7581227436823105,\n",
       " 'RTE_slice:slice_temporal_preposition_ind/SuperGLUE/valid/f1': 0.1951219512195122,\n",
       " 'RTE_slice:slice_temporal_preposition_pred/SuperGLUE/valid/accuracy': 0.8333333333333334,\n",
       " 'RTE_slice:slice_possessive_preposition_ind/SuperGLUE/valid/f1': 0.29885057471264365,\n",
       " 'RTE_slice:slice_possessive_preposition_pred/SuperGLUE/valid/accuracy': 0.696969696969697,\n",
       " 'RTE_slice:slice_is_comparative_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_is_comparative_pred/SuperGLUE/valid/accuracy': 0.7096774193548387,\n",
       " 'RTE_slice:slice_is_quantification_ind/SuperGLUE/valid/f1': 0.29059829059829057,\n",
       " 'RTE_slice:slice_is_quantification_pred/SuperGLUE/valid/accuracy': 0.6818181818181818,\n",
       " 'RTE_slice:slice_where_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_where_pred/SuperGLUE/valid/accuracy': 0.7777777777777778,\n",
       " 'RTE_slice:slice_who_ind/SuperGLUE/valid/f1': 0.24,\n",
       " 'RTE_slice:slice_who_pred/SuperGLUE/valid/accuracy': 0.7222222222222222,\n",
       " 'RTE_slice:slice_what_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_what_pred/SuperGLUE/valid/accuracy': 0.2857142857142857,\n",
       " 'RTE_slice:slice_when_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_when_pred/SuperGLUE/valid/accuracy': 0.75,\n",
       " 'RTE_slice:slice_and_ind/SuperGLUE/valid/f1': 0.8088642659279779,\n",
       " 'RTE_slice:slice_and_pred/SuperGLUE/valid/accuracy': 0.7692307692307693,\n",
       " 'RTE_slice:slice_or_ind/SuperGLUE/valid/f1': 0.8952772073921972,\n",
       " 'RTE_slice:slice_or_pred/SuperGLUE/valid/accuracy': 0.7443946188340808,\n",
       " 'RTE_slice:slice_but_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_but_pred/SuperGLUE/valid/accuracy': 0.6538461538461539,\n",
       " 'RTE_slice:slice_multiple_articles_ind/SuperGLUE/valid/f1': 0.8658823529411765,\n",
       " 'RTE_slice:slice_multiple_articles_pred/SuperGLUE/valid/accuracy': 0.7653061224489796,\n",
       " 'RTE_slice:slice_short_hypothesis_ind/SuperGLUE/valid/f1': 0.33333333333333337,\n",
       " 'RTE_slice:slice_short_hypothesis_pred/SuperGLUE/valid/accuracy': 0.6666666666666666,\n",
       " 'RTE_slice:slice_long_hypothesis_ind/SuperGLUE/valid/f1': 0.39999999999999997,\n",
       " 'RTE_slice:slice_long_hypothesis_pred/SuperGLUE/valid/accuracy': 0.8181818181818182,\n",
       " 'RTE_slice:slice_short_premise_ind/SuperGLUE/valid/f1': 0,\n",
       " 'RTE_slice:slice_short_premise_pred/SuperGLUE/valid/accuracy': 0.8333333333333334,\n",
       " 'RTE_slice:slice_long_premise_ind/SuperGLUE/valid/f1': 0.8510638297872342,\n",
       " 'RTE_slice:slice_long_premise_pred/SuperGLUE/valid/accuracy': 0.6818181818181818,\n",
       " 'RTE_slice:base_ind/SuperGLUE/valid/f1': 1.0,\n",
       " 'RTE_slice:base_pred/SuperGLUE/valid/accuracy': 0.7581227436823105}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "slice_model.score(dataloaders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By specifying all these slicing functions at the model (in a type of shotgun approach...) we see overall improvements of **+2.2 accuracy points**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
