{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel Workshop: Augmentation Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Getting started\n",
    "\n",
    "In this tutorial, we'll explore augmenting training datasets using transformation functions (TFs). We'll focus on the Words in Context task from SuperGLUE. But first, we'll take care of a few imports and defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from snorkel.augmentation.apply import PandasTFApplier\n",
    "from snorkel.augmentation.policy import RandomAugmentationPolicy\n",
    "from snorkel.augmentation.tf import transformation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"cwd\" in globals():\n",
    "    cwd = Path(os.getcwd())\n",
    "sys.path.insert(0, str(cwd.parents[0]))\n",
    "\n",
    "from dataloaders import get_jsonl_path\n",
    "from superglue_parsers.wic import get_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "task_name = \"WiC\"\n",
    "data_dir = os.environ.get(\"SUPERGLUEDATA\", os.path.join(str(cwd.parents[0]), \"data\"))\n",
    "split = \"train\"\n",
    "max_data_samples = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "We'll load the WiC data from our local download and construct a Pandas DataFrame with it. Just as a quick check, let's take a look at some of the first few entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_idx</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_idx</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>2</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>1</td>\n",
       "      <td>carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>6</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>0</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "      <td>2</td>\n",
       "      <td>break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>8</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "      <td>4</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>1</td>\n",
       "      <td>The French Academy .</td>\n",
       "      <td>2</td>\n",
       "      <td>academy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label pos                                       sentence1  \\\n",
       "0    0  False   V              You must carry your camping gear .   \n",
       "1    1  False   V  Messages must go through diplomatic channels .   \n",
       "2    2  False   V                                Break an alibi .   \n",
       "3    3   True   N         He wore a jock strap with a metal cup .   \n",
       "4    4  False   N                          The Academy of Music .   \n",
       "\n",
       "   sentence1_idx                                          sentence2  \\\n",
       "0              2                    Sound carries well over water .   \n",
       "1              2   Do you think the sofa will go through the door ?   \n",
       "2              0  The wholesaler broke the container loads into ...   \n",
       "3              8            Bees filled the waxen cups with honey .   \n",
       "4              1                               The French Academy .   \n",
       "\n",
       "   sentence2_idx     word  \n",
       "0              1    carry  \n",
       "1              6       go  \n",
       "2              2    break  \n",
       "3              4      cup  \n",
       "4              2  academy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_path = get_jsonl_path(data_dir, task_name, split)\n",
    "wic_df = pd.DataFrame.from_records(get_rows(jsonl_path, max_data_samples))\n",
    "wic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing transformation functions\n",
    "\n",
    "Let's write our first transformation function. A common approach in NLP tasks is to replace important words with synonyms. Here, we'll replace the keyword in the two sentences with a new word randomly sampled from a synonym set. We'll filter out complicated phrases and different parts-of-speech from our synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll write a helper function to execute the core logic of our TF. Given the key word and its part-of-speech, it calls `nltk`'s wordnet tooling to create a filtered set of synonym words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "def get_filtered_syns(word, pos):\n",
    "    # Use Wordnet to find synonyms and filter out\n",
    "    # synonyms that are\n",
    "    #  * the same word as the original\n",
    "    #  * composed of multiple words\n",
    "    #  * different POS from the original\n",
    "    syns = wordnet.synsets(word)\n",
    "    syns_filtered = set()\n",
    "    for s in syns:\n",
    "        name_parts = s.name().split(\".\")\n",
    "        s_word = name_parts[0]\n",
    "        same_pos = name_parts[1] == pos.lower()\n",
    "        if s_word != word and (\"_\" not in s_word) and same_pos:\n",
    "            syns_filtered.add(s_word)\n",
    "    return list(syns_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a simple example to verify functionality. As expected, we get different synonyms for when \"stream\" is used as a verb and as a noun. Try out a few more words. It's important to note that this method doesn't provide perfect substitutions. However, they can still help with training. For more information, see [this blog post](https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'stream' (verb): ['pour']\n",
      "Synonyms for 'stream' (noun): ['flow', 'current']\n"
     ]
    }
   ],
   "source": [
    "word = \"stream\"\n",
    "\n",
    "print(f\"Synonyms for '{word}' (verb):\", get_filtered_syns(word, \"V\"))\n",
    "print(f\"Synonyms for '{word}' (noun):\", get_filtered_syns(word, \"N\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll wrap out helper in a transformation function. In addition to sampling from the generated synonym set, we need to reconstruct our example. Note that the TF returns `None` if there's no available transformation. This happens if there are no valid synonyms, or if the key word appears in different forms between the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformation_function\n",
    "def replace_word(x):\n",
    "    # Break up sentence into tokens\n",
    "    sentence1_tokens = x.sentence1.split()\n",
    "    sentence2_tokens = x.sentence2.split()\n",
    "    sentence1_instance = sentence1_tokens[x.sentence1_idx]\n",
    "    sentence2_instance = sentence2_tokens[x.sentence2_idx]\n",
    "    # Check if any word forms are different\n",
    "    if len({sentence1_instance, sentence2_instance, x.word}) > 1:\n",
    "        return None\n",
    "    # Get and filter synonyms, then randomly sample\n",
    "    syns = get_filtered_syns(x.word, x.pos)\n",
    "    if len(syns) == 0:\n",
    "        return None\n",
    "    syn = random.choice(syns)\n",
    "    # Swap in synonym\n",
    "    sentence1_tokens[x.sentence1_idx] = syn\n",
    "    sentence2_tokens[x.sentence2_idx] = syn\n",
    "    # Reconstruct example and return\n",
    "    x.sentence1 = \" \".join(sentence1_tokens)\n",
    "    x.sentence2 = \" \".join(sentence2_tokens)\n",
    "    x.word = syn\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our transformation function\n",
    "\n",
    "In order to apply our TF, we need two things: a policy and an applier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Policy_\n",
    "\n",
    "The policy dictates how the TFs should be composed in a sequence. Basic data augmentation systems use a random policy that applies a randomly sampled sequence of transformations to the input training example. Augmentation policies can also be learned using [TANDA](https://hazyresearch.github.io/snorkel/blog/tanda.html) and other related techniques. Here, since we only have one TF, we can use just about any policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [replace_word]\n",
    "policy = RandomAugmentationPolicy(len([replace_word]), sequence_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Applier_\n",
    "\n",
    "The applier takes our TFs and policy, and applies them to a DataFrame of examples. We'll specify that we want 1 transformed example per original, and that we want to keep the original as well. If our TF returns `None`, there won't be a transformed example in our output DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 800.17it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "\n",
    "applier = PandasTFApplier(tfs, policy, k=1, keep_original=True)\n",
    "wic_df_synonym = applier.apply(wic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_idx</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_idx</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>2</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>1</td>\n",
       "      <td>carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>6</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Messages must move through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think the sofa will move through the do...</td>\n",
       "      <td>6</td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>0</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "      <td>2</td>\n",
       "      <td>break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>8</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "      <td>4</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>1</td>\n",
       "      <td>The French Academy .</td>\n",
       "      <td>2</td>\n",
       "      <td>academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Set the table .</td>\n",
       "      <td>0</td>\n",
       "      <td>To set glass in a sash .</td>\n",
       "      <td>1</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>Starch clothes .</td>\n",
       "      <td>0</td>\n",
       "      <td>She starched her blouses .</td>\n",
       "      <td>1</td>\n",
       "      <td>starch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Do you take sugar in your coffee ?</td>\n",
       "      <td>2</td>\n",
       "      <td>A reading was taken of the earth 's tremors .</td>\n",
       "      <td>3</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>I try to avoid the company of gamblers .</td>\n",
       "      <td>3</td>\n",
       "      <td>We avoided the ball .</td>\n",
       "      <td>1</td>\n",
       "      <td>avoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>He got clearance to travel to America , even t...</td>\n",
       "      <td>2</td>\n",
       "      <td>The plane got clearance from air traffic contr...</td>\n",
       "      <td>3</td>\n",
       "      <td>clearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>He got headroom to travel to America , even th...</td>\n",
       "      <td>2</td>\n",
       "      <td>The plane got headroom from air traffic contro...</td>\n",
       "      <td>3</td>\n",
       "      <td>headroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>Come out of the closet !</td>\n",
       "      <td>0</td>\n",
       "      <td>He came singing down the road .</td>\n",
       "      <td>1</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>Before laying sod on that clay , the ground ne...</td>\n",
       "      <td>13</td>\n",
       "      <td>The dictionary 's coverage of standard English...</td>\n",
       "      <td>3</td>\n",
       "      <td>coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>Her death came as a terrible shock .</td>\n",
       "      <td>1</td>\n",
       "      <td>He had two deaths on his conscience .</td>\n",
       "      <td>3</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The despite in which outsiders were held is le...</td>\n",
       "      <td>1</td>\n",
       "      <td>She wanted neither favor nor despite .</td>\n",
       "      <td>5</td>\n",
       "      <td>despite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The contempt in which outsiders were held is l...</td>\n",
       "      <td>1</td>\n",
       "      <td>She wanted neither favor nor contempt .</td>\n",
       "      <td>5</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>A school of small glittering fish swam by .</td>\n",
       "      <td>1</td>\n",
       "      <td>The divers encountered a huge school of macker...</td>\n",
       "      <td>5</td>\n",
       "      <td>school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>We should go farther in this matter .</td>\n",
       "      <td>2</td>\n",
       "      <td>She went through a lot of trouble .</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>The United Nations must have the power to prop...</td>\n",
       "      <td>11</td>\n",
       "      <td>Recent federal action undermined the segregati...</td>\n",
       "      <td>2</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Fall by the wayside .</td>\n",
       "      <td>0</td>\n",
       "      <td>The cities fell to the enemy .</td>\n",
       "      <td>2</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>This dough does not work easily .</td>\n",
       "      <td>4</td>\n",
       "      <td>Work the phones .</td>\n",
       "      <td>0</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The armies met in the shock of battle .</td>\n",
       "      <td>5</td>\n",
       "      <td>The train hit the buffers with a great shock .</td>\n",
       "      <td>8</td>\n",
       "      <td>shock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>The armies met in the daze of battle .</td>\n",
       "      <td>5</td>\n",
       "      <td>The train hit the buffers with a great daze .</td>\n",
       "      <td>8</td>\n",
       "      <td>daze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>This speech did n't play well with the America...</td>\n",
       "      <td>4</td>\n",
       "      <td>Play football .</td>\n",
       "      <td>0</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label pos                                          sentence1  \\\n",
       "0    0  False   V                 You must carry your camping gear .   \n",
       "1    1  False   V     Messages must go through diplomatic channels .   \n",
       "1    1  False   V   Messages must move through diplomatic channels .   \n",
       "2    2  False   V                                   Break an alibi .   \n",
       "3    3   True   N            He wore a jock strap with a metal cup .   \n",
       "4    4  False   N                             The Academy of Music .   \n",
       "5    5  False   V                                    Set the table .   \n",
       "6    6   True   V                                   Starch clothes .   \n",
       "7    7  False   V                 Do you take sugar in your coffee ?   \n",
       "8    8   True   V           I try to avoid the company of gamblers .   \n",
       "9    9   True   N  He got clearance to travel to America , even t...   \n",
       "9    9   True   N  He got headroom to travel to America , even th...   \n",
       "10  10   True   V                           Come out of the closet !   \n",
       "11  11   True   N  Before laying sod on that clay , the ground ne...   \n",
       "12  12  False   N               Her death came as a terrible shock .   \n",
       "13  13  False   N  The despite in which outsiders were held is le...   \n",
       "13  13  False   N  The contempt in which outsiders were held is l...   \n",
       "14  14   True   N        A school of small glittering fish swam by .   \n",
       "15  15   True   V              We should go farther in this matter .   \n",
       "16  16   True   N  The United Nations must have the power to prop...   \n",
       "17  17  False   V                              Fall by the wayside .   \n",
       "18  18  False   V                  This dough does not work easily .   \n",
       "19  19  False   N            The armies met in the shock of battle .   \n",
       "19  19  False   N             The armies met in the daze of battle .   \n",
       "20  20  False   V  This speech did n't play well with the America...   \n",
       "\n",
       "   sentence1_idx                                          sentence2  \\\n",
       "0              2                    Sound carries well over water .   \n",
       "1              2   Do you think the sofa will go through the door ?   \n",
       "1              2  Do you think the sofa will move through the do...   \n",
       "2              0  The wholesaler broke the container loads into ...   \n",
       "3              8            Bees filled the waxen cups with honey .   \n",
       "4              1                               The French Academy .   \n",
       "5              0                           To set glass in a sash .   \n",
       "6              0                         She starched her blouses .   \n",
       "7              2      A reading was taken of the earth 's tremors .   \n",
       "8              3                              We avoided the ball .   \n",
       "9              2  The plane got clearance from air traffic contr...   \n",
       "9              2  The plane got headroom from air traffic contro...   \n",
       "10             0                    He came singing down the road .   \n",
       "11            13  The dictionary 's coverage of standard English...   \n",
       "12             1              He had two deaths on his conscience .   \n",
       "13             1             She wanted neither favor nor despite .   \n",
       "13             1            She wanted neither favor nor contempt .   \n",
       "14             1  The divers encountered a huge school of macker...   \n",
       "15             2                She went through a lot of trouble .   \n",
       "16            11  Recent federal action undermined the segregati...   \n",
       "17             0                     The cities fell to the enemy .   \n",
       "18             4                                  Work the phones .   \n",
       "19             5     The train hit the buffers with a great shock .   \n",
       "19             5      The train hit the buffers with a great daze .   \n",
       "20             4                                    Play football .   \n",
       "\n",
       "   sentence2_idx       word  \n",
       "0              1      carry  \n",
       "1              6         go  \n",
       "1              6       move  \n",
       "2              2      break  \n",
       "3              4        cup  \n",
       "4              2    academy  \n",
       "5              1        set  \n",
       "6              1     starch  \n",
       "7              3       take  \n",
       "8              1      avoid  \n",
       "9              3  clearance  \n",
       "9              3   headroom  \n",
       "10             1       come  \n",
       "11             3   coverage  \n",
       "12             3      death  \n",
       "13             5    despite  \n",
       "13             5   contempt  \n",
       "14             5     school  \n",
       "15             1         go  \n",
       "16             2     action  \n",
       "17             2       fall  \n",
       "18             0       work  \n",
       "19             8      shock  \n",
       "19             8       daze  \n",
       "20             0       play  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wic_df_synonym.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing more transformation functions\n",
    "\n",
    "This is perhaps the simplest TF we can write for WiC. The two sentences in each training example are unordered, so swapping their order doesn't change the label. Since the model architecture we're using is not invariant to input order, we can generate a new, unique training example by simply swapping the two sentences. We'll apply this to our DataFrame with synonym-swapped examples as well so that we get new examples for those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformation_function\n",
    "def swap_sentences(x):\n",
    "    x.sentence1, x.sentence2 = x.sentence2, x.sentence1\n",
    "    x.sentence1_idx, x.sentence2_idx = x.sentence2_idx, x.sentence1_idx\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll define our policy and applier, then create our augmented DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 1289.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_idx</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_idx</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>2</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>1</td>\n",
       "      <td>carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>1</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>2</td>\n",
       "      <td>carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>6</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>6</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>Messages must move through diplomatic channels .</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think the sofa will move through the do...</td>\n",
       "      <td>6</td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx  label pos                                         sentence1  \\\n",
       "0   0  False   V                You must carry your camping gear .   \n",
       "0   0  False   V                   Sound carries well over water .   \n",
       "1   1  False   V    Messages must go through diplomatic channels .   \n",
       "1   1  False   V  Do you think the sofa will go through the door ?   \n",
       "1   1  False   V  Messages must move through diplomatic channels .   \n",
       "\n",
       "  sentence1_idx                                          sentence2  \\\n",
       "0             2                    Sound carries well over water .   \n",
       "0             1                 You must carry your camping gear .   \n",
       "1             2   Do you think the sofa will go through the door ?   \n",
       "1             6     Messages must go through diplomatic channels .   \n",
       "1             2  Do you think the sofa will move through the do...   \n",
       "\n",
       "  sentence2_idx   word  \n",
       "0             1  carry  \n",
       "0             2  carry  \n",
       "1             6     go  \n",
       "1             2     go  \n",
       "1             6   move  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = [swap_sentences]\n",
    "policy = RandomAugmentationPolicy(len(tfs), sequence_length=1)\n",
    "applier = PandasTFApplier(tfs, policy, k=1, keep_original=True)\n",
    "wic_df_swapped = applier.apply(wic_df_synonym)\n",
    "wic_df_swapped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now it's your turn!\n",
    "\n",
    "Try writing a transformation function of your own! Remember, it should output either a new example or `None`. Get creative! Just like we wrapped a resource from `nltk` in our synonym-swapping TF, we can wrap any other existing language model, etc. For more ideas, check out this [blog post](https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610)\n",
    "or this [more advanced blog post](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28).\n",
    "\n",
    "We've included some starter code for inspiration:\n",
    "```\n",
    "@transformation_function\n",
    "def my_tf(x):\n",
    "    return x\n",
    "    \n",
    "tfs = [replace_word, my_tf]\n",
    "policy = RandomAugmentationPolicy(len(tfs), sequence_length=2)\n",
    "applier = PandasTFApplier(tfs, policy, k=2, keep_original=True)\n",
    "wic_df_augmented = applier.apply(wic_df)\n",
    "wic_df_augmented.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with augmented data\n",
    "\n",
    "Feeling ambitious? Try training a WiC model with your augmented data.\n",
    "\n",
    "**_Important_**: to get the full training set, you'll need to re-execute from the beginning and set `max_data_samples` to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct our dataset with the default helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.mtl.data import MultitaskDataLoader\n",
    "from snorkel.mtl.model import MultitaskModel\n",
    "from snorkel.mtl.snorkel_config import default_config as config\n",
    "from snorkel.mtl.trainer import Trainer\n",
    "\n",
    "import superglue_tasks\n",
    "from dataloaders import get_dataloaders\n",
    "from superglue_parsers.wic import parse_from_rows\n",
    "from tokenizer import get_tokenizer\n",
    "\n",
    "\n",
    "max_sequence_length = 256\n",
    "batch_size = 4\n",
    "tokenizer_name = \"bert-large-cased\"\n",
    "tokenizer = get_tokenizer(tokenizer_name)\n",
    "\n",
    "# Construct training dataloader from augmented DF\n",
    "rows = wic_df_swapped.to_dict(\"records\")\n",
    "dataset = parse_from_rows(rows, tokenizer, max_sequence_length)\n",
    "train_dataloader = MultitaskDataLoader(\n",
    "    task_to_label_dict={task_name: \"labels\"},\n",
    "    dataset=dataset,\n",
    "    split=\"train\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_dataloader = get_dataloaders(\n",
    "    data_dir,\n",
    "    task_name=task_name,\n",
    "    splits=[\"valid\"],\n",
    "    max_data_samples=None,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    batch_size=batch_size,\n",
    ")[0]\n",
    "\n",
    "dataloaders = [train_dataloader, valid_dataloader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the slicing tutorial, we'll use the Snorkel API to configure a BERT model to train our natural language understanding model. This again comes from [huggingface's BERT library](https://github.com/huggingface/pytorch-pretrained-BERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(name=WiC)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = \"bert-large-cased\"\n",
    "base_task = superglue_tasks.task_funcs[task_name](bert_model)\n",
    "tasks = [base_task]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultitaskModel(\n",
    "    name=f\"SuperGLUE\",\n",
    "    tasks=tasks, \n",
    "    dataparallel=False,\n",
    "    device=-1 # use CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to uncomment this block to experiment with it yourself! It will take a while to train on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(**config)\n",
    "# trainer.train_model(model, dataloaders)\n",
    "# model.save(\"./model_with_data_augmentation.pth\")\n",
    "# model.score(dataloaders[1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
